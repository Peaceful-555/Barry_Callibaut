{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ OpenAI Response:\n",
      " Sure! Letâ€™s break it down step by step in simple terms:\n",
      "\n",
      "### 1. **Artificial Intelligence (AI):**\n",
      "   - **What it is:** AI is the big umbrella term. It refers to the idea of creating machines or software that can perform tasks that typically require human intelligence.\n",
      "   - **Examples:** AI includes things like recognizing speech, playing chess, understanding language, or making decisions.\n",
      "   - **Key point:** AI is the broadest concept, and it includes many different approaches and techniques to make machines \"smart.\"\n",
      "\n",
      "---\n",
      "\n",
      "### 2. **Machine Learning (ML):**\n",
      "   - **What it is:** Machine learning is a subset of AI. Itâ€™s a way to teach machines to learn from data instead of being explicitly programmed for every single task.\n",
      "   - **How it works:** You give the machine a lot of data, and it finds patterns or relationships in that data. Then, it uses those patterns to make predictions or decisions.\n",
      "   - **Examples:** \n",
      "     - A spam filter that learns to recognize spam emails based on examples of spam and non-spam emails.\n",
      "     - A recommendation system (like Netflix or Amazon) that suggests movies or products based on your past behavior.\n",
      "   - **Key point:** Machine learning is one way to achieve AI by letting machines learn from data.\n",
      "\n",
      "---\n",
      "\n",
      "### 3. **Deep Learning (DL):**\n",
      "   - **What it is:** Deep learning is a subset of machine learning. It uses a special kind of algorithm called a **neural network**, which is inspired by how the human brain works.\n",
      "   - **How it works:** Deep learning models have many layers of \"neurons\" (hence the term \"deep\"). These layers process data step by step, learning increasingly complex patterns. For example, in image recognition:\n",
      "     - The first layer might detect edges.\n",
      "     - The next layer might detect shapes.\n",
      "     - The final layers might recognize objects like \"cat\" or \"dog.\"\n",
      "   - **Examples:**\n",
      "     - Self-driving cars use deep learning to recognize pedestrians, traffic signs, and other vehicles.\n",
      "     - Voice assistants like Siri or Alexa use deep learning to understand and respond to your voice.\n",
      "   - **Key point:** Deep learning is a more advanced and powerful type of machine learning, especially for tasks like image recognition, speech processing, and natural language understanding.\n",
      "\n",
      "---\n",
      "\n",
      "### How They Relate:\n",
      "Think of it like this:\n",
      "- **AI** is the goal: making machines smart.\n",
      "- **Machine learning** is one way to achieve AI: teaching machines to learn from data.\n",
      "- **Deep learning** is a more advanced type of machine learning: using neural networks with many layers to solve really complex problems.\n",
      "\n",
      "In short:\n",
      "- **AI** is the big picture.\n",
      "- **ML** is a tool within AI.\n",
      "- **DL** is a specialized tool within ML.\n"
     ]
    }
   ],
   "source": [
    "# openai_client.py\n",
    "\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "from dotenv import load_dotenv\n",
    "from azure.identity import ClientSecretCredential\n",
    "from langchain_openai import AzureChatOpenAI, AzureOpenAIEmbeddings\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Configure logging\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# Azure Credentials\n",
    "credential = ClientSecretCredential(\n",
    "    tenant_id=os.getenv(\"AZURE_TENANT_ID\"),\n",
    "    client_id=os.getenv(\"AZURE_CLIENT_ID\"),\n",
    "    client_secret=os.getenv(\"AZURE_CLIENT_SECRET\"),\n",
    ")\n",
    "\n",
    "# Globals\n",
    "TOKEN_USAGE = {}\n",
    "TOTAL_API_CALL = 0\n",
    "AZURE_OPENAI_DEPLOYMENT = os.getenv(\"AZURE_OPENAI_DEPLOYMENT\")\n",
    "\n",
    "# Rebuild model to fix potential Pydantic issues\n",
    "AzureChatOpenAI.model_rebuild()\n",
    "\n",
    "# Initialize Chat LLM client\n",
    "def llm():\n",
    "    access_token = credential.get_token(\"https://cognitiveservices.azure.com/.default\").token\n",
    "    return AzureChatOpenAI(\n",
    "        azure_deployment=os.getenv(\"AZURE_OPENAI_DEPLOYMENT\"),\n",
    "        api_version=os.getenv(\"AZURE_API_VERSION\"),\n",
    "        temperature=0,\n",
    "        max_tokens=None,\n",
    "        timeout=None,\n",
    "        max_retries=2,\n",
    "        openai_api_key=access_token,\n",
    "        azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    )\n",
    "\n",
    "# Initialize base OpenAI client\n",
    "def openai_llm():\n",
    "    access_token = credential.get_token(\"https://cognitiveservices.azure.com/.default\").token\n",
    "    return AzureOpenAI(\n",
    "        azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "        api_version=os.getenv(\"AZURE_API_VERSION\"),\n",
    "        api_key=access_token,\n",
    "    )\n",
    "\n",
    "# Initialize embeddings client\n",
    "def embeddings():\n",
    "    access_token = credential.get_token(\"https://cognitiveservices.azure.com/.default\").token\n",
    "    return AzureOpenAIEmbeddings(\n",
    "        model=os.getenv(\"EMBEDDING_AZURE_OPENAI_DEPLOYMENT\"),\n",
    "        azure_endpoint=os.getenv(\"EMBEDDING_AZURE_OPENAI_ENDPOINT\"),\n",
    "        openai_api_version=os.getenv(\"AZURE_API_VERSION\"),\n",
    "        api_key=access_token,\n",
    "    )\n",
    "\n",
    "# Token usage logger\n",
    "def add_token_usage_logs(llm_output, message=\"\"):\n",
    "    token_usage_string = \"\"\n",
    "    for key, value in llm_output.to_dict().get(\"usage\", {}).items():\n",
    "        token_usage_string += f\"{key}: {value} | \"\n",
    "    logger.info(f\"{message} {token_usage_string}\")\n",
    "    return llm_output.to_dict().get(\"usage\", {}).get(\"total_tokens\", 0)\n",
    "\n",
    "# Send OpenAI call with sys + user prompt\n",
    "def openai_call(sys_prompt, prompt_struc, deployment_name=AZURE_OPENAI_DEPLOYMENT, additional_message=\"\"):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": sys_prompt},\n",
    "        {\"role\": \"user\", \"content\": prompt_struc},\n",
    "    ]\n",
    "    return _call_openai(messages, deployment_name, additional_message)\n",
    "\n",
    "# Send OpenAI call with custom message structure\n",
    "def openai_call_only_message(messages, deployment_name=AZURE_OPENAI_DEPLOYMENT, additional_message=\"\"):\n",
    "    return _call_openai(messages, deployment_name, additional_message)\n",
    "\n",
    "# Retry wrapper for OpenAI calls\n",
    "def _call_openai(messages, deployment_name, additional_message):\n",
    "    global TOTAL_API_CALL\n",
    "    max_retries = 5\n",
    "    for current_retry in range(max_retries):\n",
    "        try:\n",
    "            time.sleep(5)\n",
    "            logger.info(f\"Calling OpenAI API with deployment: {deployment_name}, Retry: {current_retry + 1}\")\n",
    "            start_time = time.time()\n",
    "            response = openai_llm().chat.completions.create(\n",
    "                model=deployment_name,\n",
    "                messages=messages,\n",
    "                temperature=0,\n",
    "                # response_format removed for non-JSON prompt compatibility\n",
    "            )\n",
    "            TOTAL_API_CALL += 1\n",
    "            duration = round(time.time() - start_time, 3)\n",
    "            output = response.choices[0].message.content\n",
    "            if output:\n",
    "                msg = f\"OPENAI CALL MESSAGE: Retry {current_retry + 1} | Func: {additional_message} | Duration: {duration}s\"\n",
    "                total_tokens = add_token_usage_logs(response, message=msg)\n",
    "                TOKEN_USAGE[additional_message] = TOKEN_USAGE.get(additional_message, 0) + total_tokens\n",
    "                logger.info(f\"Token Usage Summary: {TOKEN_USAGE}\")\n",
    "                print(\"\\nðŸ”¹ OpenAI Response:\\n\", output)\n",
    "                return output\n",
    "        except Exception as e:\n",
    "            logger.error(f\"OpenAI Call Error: {e}\")\n",
    "    logger.warning(\"Maximum retries reached. No response returned.\")\n",
    "    return None\n",
    "\n",
    "# Embedding generation with retry\n",
    "def get_embedding(text, additional_message=\"\"):\n",
    "    max_retries = 5\n",
    "    for current_retry in range(max_retries):\n",
    "        try:\n",
    "            logger.info(f\"Calling Embedding API | Retry: {current_retry + 1} | Caller: {additional_message}\")\n",
    "            time.sleep(5)\n",
    "            return embeddings().embed_query(text)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Embedding Error: {e}\")\n",
    "    logger.warning(\"Failed to get embedding after retries.\")\n",
    "    return None\n",
    "\n",
    "\n",
    "# ðŸ”¹ Sample Execution for Direct Prompt Testing\n",
    "if __name__ == \"__main__\":\n",
    "    system_prompt = \"You are a helpful assistant that explains technical concepts in simple terms.\"\n",
    "    user_prompt = \"Explain the difference between AI, machine learning, and deep learning.\"\n",
    "\n",
    "    openai_call(\n",
    "        sys_prompt=system_prompt,\n",
    "        prompt_struc=user_prompt,\n",
    "        additional_message=\"sample_direct_prompt\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting langchain_openai\n",
      "  Downloading langchain_openai-0.3.28-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langchain-core<1.0.0,>=0.3.68 (from langchain_openai)\n",
      "  Downloading langchain_core-0.3.69-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting openai<2.0.0,>=1.86.0 (from langchain_openai)\n",
      "  Downloading openai-1.96.1-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting tiktoken<1,>=0.7 (from langchain_openai)\n",
      "  Downloading tiktoken-0.9.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Collecting langsmith>=0.3.45 (from langchain-core<1.0.0,>=0.3.68->langchain_openai)\n",
      "  Downloading langsmith-0.4.6-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/jaydutonde/Library/Python/3.9/lib/python/site-packages (from langchain-core<1.0.0,>=0.3.68->langchain_openai) (9.1.2)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<1.0.0,>=0.3.68->langchain_openai)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting PyYAML>=5.3 (from langchain-core<1.0.0,>=0.3.68->langchain_openai)\n",
      "  Downloading PyYAML-6.0.2-cp39-cp39-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/jaydutonde/Library/Python/3.9/lib/python/site-packages (from langchain-core<1.0.0,>=0.3.68->langchain_openai) (4.12.2)\n",
      "Requirement already satisfied: packaging>=23.2 in /Users/jaydutonde/Library/Python/3.9/lib/python/site-packages (from langchain-core<1.0.0,>=0.3.68->langchain_openai) (24.2)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in /Users/jaydutonde/Library/Python/3.9/lib/python/site-packages (from langchain-core<1.0.0,>=0.3.68->langchain_openai) (2.11.4)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.68->langchain_openai)\n",
      "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/jaydutonde/Library/Python/3.9/lib/python/site-packages (from openai<2.0.0,>=1.86.0->langchain_openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/jaydutonde/Library/Python/3.9/lib/python/site-packages (from openai<2.0.0,>=1.86.0->langchain_openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/jaydutonde/Library/Python/3.9/lib/python/site-packages (from openai<2.0.0,>=1.86.0->langchain_openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/jaydutonde/Library/Python/3.9/lib/python/site-packages (from openai<2.0.0,>=1.86.0->langchain_openai) (0.9.0)\n",
      "Requirement already satisfied: sniffio in /Users/jaydutonde/Library/Python/3.9/lib/python/site-packages (from openai<2.0.0,>=1.86.0->langchain_openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/jaydutonde/Library/Python/3.9/lib/python/site-packages (from openai<2.0.0,>=1.86.0->langchain_openai) (4.67.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/jaydutonde/Library/Python/3.9/lib/python/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.86.0->langchain_openai) (1.2.2)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/jaydutonde/Library/Python/3.9/lib/python/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.86.0->langchain_openai) (3.10)\n",
      "Requirement already satisfied: certifi in /Users/jaydutonde/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.86.0->langchain_openai) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/jaydutonde/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.86.0->langchain_openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/jaydutonde/Library/Python/3.9/lib/python/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.86.0->langchain_openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/jaydutonde/Library/Python/3.9/lib/python/site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.68->langchain_openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/jaydutonde/Library/Python/3.9/lib/python/site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.68->langchain_openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/jaydutonde/Library/Python/3.9/lib/python/site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.68->langchain_openai) (0.4.0)\n",
      "Collecting regex>=2022.1.18 (from tiktoken<1,>=0.7->langchain_openai)\n",
      "  Downloading regex-2024.11.6-cp39-cp39-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests>=2.26.0 in /Users/jaydutonde/Library/Python/3.9/lib/python/site-packages (from tiktoken<1,>=0.7->langchain_openai) (2.32.3)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.68->langchain_openai)\n",
      "  Downloading orjson-3.11.0-cp39-cp39-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl.metadata (42 kB)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/jaydutonde/Library/Python/3.9/lib/python/site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.68->langchain_openai) (1.0.0)\n",
      "Collecting zstandard<0.24.0,>=0.23.0 (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.68->langchain_openai)\n",
      "  Downloading zstandard-0.23.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/jaydutonde/Library/Python/3.9/lib/python/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/jaydutonde/Library/Python/3.9/lib/python/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (1.26.20)\n",
      "Downloading langchain_openai-0.3.28-py3-none-any.whl (70 kB)\n",
      "Downloading langchain_core-0.3.69-py3-none-any.whl (441 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading openai-1.96.1-py3-none-any.whl (757 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m757.5/757.5 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tiktoken-0.9.0-cp39-cp39-macosx_11_0_arm64.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading langsmith-0.4.6-py3-none-any.whl (367 kB)\n",
      "Downloading orjson-3.11.0-cp39-cp39-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl (241 kB)\n",
      "Downloading zstandard-0.23.0-cp39-cp39-macosx_11_0_arm64.whl (633 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m633.7/633.7 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading PyYAML-6.0.2-cp39-cp39-macosx_11_0_arm64.whl (172 kB)\n",
      "Downloading regex-2024.11.6-cp39-cp39-macosx_11_0_arm64.whl (284 kB)\n",
      "Installing collected packages: zstandard, regex, PyYAML, orjson, jsonpointer, tiktoken, jsonpatch, openai, langsmith, langchain-core, langchain_openai\n",
      "\u001b[2K  Attempting uninstall: openai\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 5/11\u001b[0m [tiktoken]\n",
      "\u001b[2K    Found existing installation: openai 1.78.0â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 5/11\u001b[0m [tiktoken]\n",
      "\u001b[2K    Uninstalling openai-1.78.0:â•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 5/11\u001b[0m [tiktoken]\n",
      "\u001b[2K      Successfully uninstalled openai-1.78.0â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 5/11\u001b[0m [tiktoken]\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m11/11\u001b[0m [langchain_openai][langchain-core]\n",
      "\u001b[1A\u001b[2KSuccessfully installed PyYAML-6.0.2 jsonpatch-1.33 jsonpointer-3.0.0 langchain-core-0.3.69 langchain_openai-0.3.28 langsmith-0.4.6 openai-1.96.1 orjson-3.11.0 regex-2024.11.6 tiktoken-0.9.0 zstandard-0.23.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"title\": \"R&D Supplier Brief - Chocolate Coating for Murray Street.pdf\",\n",
      "    \"pagenum\": 1,\n",
      "    \"content\": \"Bulla\\u00ae FAMILY DAIRY SINCE 1910 - Bulla Dairy Foods - R&D Supplier Brief Form 1. PROJECT INFORMATION Date 7-May-25 Technical Lead Michelle Gardiner Project Number 230513 Project Name Murray St Chunky Sticks Project Type New Product Development 2. FINISHED PRODUCT INFORMATION Brand Murray St Product/s Ice Cream Sticks and Sandwiches Competitor Products Connoisseur Classic Vanilla Ice Cream 4 Pack | 400mL Claims Material needs to be compliant for Codex Standard for Milk Chocolate. Project Objective To develop a milk chocolate coating for the purpose of enrobing ice cream sticks and sandwiches. The chocolate must have excellent melting and coating characteristics, be stable for frozen applications, and deliver a premium flavour and texture experience. It must be able to hold inclusions in the coating. When consumed, it must provide a 'snap' when bitten into. Target Shelf Life 2 Years (finished goods) 3. NEW RAW MATERIAL REQUIREMENTS Raw Material Type Food Ingredient Raw Material Description Milk Chocolate Coating Raw Material Format Kibble/button/chips Indicative Volumes 66 Tonne Year 1 10% more for year 2 Appearance Medium to light brown typical of milk chocolate Colour (Pantone Ref #) 35-45 RLU Flavour \\\" Authentic milk chocolate flavour profile, not too bitter. \\u25ab Sweet, creamy, and balanced with a cocoa-milk note. Slight natural caramel or vanilla undertones. Lingering chocolate flavour with good flavour intensity. No off-flavours (e.g. burnt, waxy, or sour). \\u25ab Aroma Typical of milk chocolate. Texture Smooth. Crisp snap when bitten into. Not chewy or soft when bitten into. DocID: 3658 Owner: Mary Sharma Version No: 9 Approved Date: 3/03/2025 [Issue Copy Site] [Issue Copy Location] Printed copies may not be the latest version unless issued Page 1 of 5\"\n",
      "  },\n",
      "  {\n",
      "    \"title\": \"R&D Supplier Brief - Chocolate Coating for Murray Street.pdf\",\n",
      "    \"pagenum\": 2,\n",
      "    \"content\": \"Bulla\\u00ae FAMILY DAIRY SINCE 1910 - Bulla Dairy Foods - R&D Supplier Brief Form Viscosity to be determined during sample assessments Cocoa Solids Initially looking to assess different percentages with 26%, 28% and 30% cocoa solids. Product needs to be compliant for Codex Standard for Milk Chocolate. Milk Solids (Non-fat) Product needs to be compliant for Codex Standard for Milk Chocolate. Fat Content Product needs to be compliant for Codex Standard for Milk Chocolate. Sugar Content Product needs to be compliant for Codex Standard for Milk Chocolate. Additives Emulsifiers (e.g., lecithin) \\\" Natural flavourings Vegetable oil - permissible amounts as per FSC guidelines in final blend PGPR (e476) - from vegetable origin. Must be below 5g/kg in final blend (0.5%). Dosage Rate in Product Approx 20g/stick Sample Quantity Required 2kg per variant initially Country of Origin Requirements none Export Markets to comply with China Processing requirements Must be able to withstand enrobing process, aswell as wrapping and boxing. The chocolate will need to maintain some softness during wrapping so it doesn't shard and break. Processing parameters: o typically 40-60\\u2103 in kibble melter for 90mins per 1000kg o Ice Cream will be approximately -37.5\\u2103 when dipped into melted chocolate o Time between dipping into chocolate and wrapping: 118 second with single index 60 seconds with double index 4. TIMINGS Launch Date 1-Sep-26 1st Sample Submission 16-Jun-25 Feedback to Supplier 30-Jun-25 2nd Sample Submission 14-Jul-25 Feedback to Supplier 28-Jul-25 Factory Trial TBC First Production TBC DocID: 3658 Owner: Mary Sharma Version No: 9 Approved Date: 3/03/2025 [Issue Copy Site] [Issue Copy Location] Printed copies may not be the latest version unless issued Page 2 of 5\"\n",
      "  },\n",
      "  {\n",
      "    \"title\": \"R&D Supplier Brief - Chocolate Coating for Murray Street.pdf\",\n",
      "    \"pagenum\": 3,\n",
      "    \"content\": \"Bulla\\u00ae FAMILY DAIRY SINCE 1910 - Bulla Dairy Foods - R&D Supplier Brief Form 5. OPERATIONAL REQUIREMENTS Delivery Site Colac as per Bulla Purchase Order Packaging Requirements 15kg bags/boxes Storage Conditions Temperature control between 15\\u2103 to 20\\u2103 Shelf Life Minimum 12 months (raw material) 6. RESTRICTIONS & CERTIFICATIONS Requirement Certification Required Specific Details Halal Certified Yes Yes Kosher No No Vegetarian Yes No Non-Palm requested by Customer Select Select NA RSPO Palm Oil Yes Yes (Segregated as a minimum) GMO Free Yes No No Artificial Colours Yes No No Artificial Flavours Yes No No Preservatives Yes No No Artificial Sweeteners Yes No Cocoa Certification Yes Yes (Please see section 12 for more details) Eggs Free Range Yes No Other certifications for Coffee, Tea, Coconut, Soy, Hazelnut. Yes Yes (Please see section 12 for more details) 7. WHITE MASS INFORMATION White Mass Type Ice Cream 8. QUALITY REQUIREMENTS Permitted allergens Milk, Soy. Standard Plate Count Max 20,000 cfu/g Salmonella Absent in 25g Enterobateriacae Max 10 cfu/g DocID: 3658 Owner: Mary Sharma Version No: 9 Approved Date: 3/03/2025 [Issue Copy Site] [Issue Copy Location] Printed copies may not be the latest version unless issued Page 3 of 5\"\n",
      "  },\n",
      "  {\n",
      "    \"title\": \"R&D Supplier Brief - Chocolate Coating for Murray Street.pdf\",\n",
      "    \"pagenum\": 4,\n",
      "    \"content\": \"Bulla\\u00ae FAMILY DAIRY SINCE 1910 - Bulla Dairy Foods - R&D Supplier Brief Form Foreign Matter Absent 9. CONTACT INFORMATION - R&D Name Michelle Gardiner Title Product Development Technologist Email Address Michelle.Gardiner@bulla.com.au Phone Number 0457 157 748 Mailing Address 91-149 Forest Street, Colac, VIC 3250, Australia. 10. CONTACT INFORMATION - PROCUREMENT Name Olivia Li Title Sourcing Manager Direct Materials Email Address Olivia.Li@Bulla.com.au Phone Number 0400 084 756 Mailing Address 15 Swann Drive, Derrimut, VIC 3030, Australia 11. MANDATORY REQUIREMENTS WITH FIRST SAMPLE SUBMISSION Specification completed in full, which must include: 1. Ingredient List 2. Allergen Status 3. Nutrition Information Panel 4. Specific Gravity / Density (if applicable) 5. Viscosity (if applicable) Material Safety Data Sheet Cost Per Kilo Unique Raw Material Status Lead Time Minimum Order Quantity DocID: 3658 Owner: Mary Sharma Version No: 9 Approved Date: 3/03/2025 [Issue Copy Site] [Issue Copy Location] Printed copies may not be the latest version unless issued Page 4 of 5\"\n",
      "  },\n",
      "  {\n",
      "    \"title\": \"R&D Supplier Brief - Chocolate Coating for Murray Street.pdf\",\n",
      "    \"pagenum\": 5,\n",
      "    \"content\": \"Bulla\\u00ae FAMILY DAIRY SINCE 1910 - Bulla Dairy Foods - R&D Supplier Brief Form 12. MANDATORY REQUIREMENTS FOR ACCEPTANCE INTO PRODUCTION Supplier brief requirements to be met No artificial trans fats and partially hydrogenated oils to be used. No high-fructose corn syrup to be used. GMO Free Irradiation Free \\u00b7 AFGC PIF 6.0 to be completed in full \\u00b7 AFGC Country of Origin Annex \\u00b7 Safety Data Sheet Secondary shelf life (i.e. acceptable number of breaches for pallecons etc.) No Carmine, Annatto, Titanium Dioxide or artificial colours (as defined by Natcol) to be used. If using Sodium Citrate (331), please ensure Tri-Sodium Citrate is used (Required for Export Markets) Use of Processed Eucheuma Seaweed (INS 407a) is not permitted please use Carrageenan (INS 407) (407a not recognised in some export countries). Flavours - Preference is to avoid flavours that are classified as 'Dangerous Goods', please investigate alternative carriers to ethanol. Palm Oil - must be Responsibly Sourced Palm Oil (RSPO) Certified (Segregated as a minimum) . All Palm Oil or ingredients containing Palm Oil must be sourced from RSPO Certified facilities and must be Segregated (SG) at a minimum by 2027. . Ingredients containing Palm Oil must RSPO Certified (SG at a minimum) throughout the entire supply chain. Cocoa - must include and provide 3rd Party Certification for Rainforest Alliance (RA), Fair Trade (FT) or Cocoa Horizons (CH). Coconut - must provide an Executive Declaration no Monkey Harvesting is occurring in Supply Chain Soy - If soy ingredient Country of Origin is in South America, then: RTRS Mass Balance Certificate for each applicable raw material ingredient supplier OR ISCC+ Mass Balance Certificate for each applicable raw material ingredient supplier OR Ingredient supplier Mass Balance certificate from approved equivalent standard Coffee, Tea & Hazelnuts - Raw Material / Ingredient Supplier's Rainforest Alliance Mass Balance Certificate OR Raw Material / Ingredient Supplier's Fairtrade Mass Balance Certificate DocID: 3658 Owner: Mary Sharma Version No: 9 Approved Date: 3/03/2025 [Issue Copy Site] [Issue Copy Location] Printed copies may not be the latest version unless issued Page 5 of 5\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "from typing import List, Dict\n",
    "from pathlib import Path\n",
    "from azure.ai.documentintelligence import DocumentIntelligenceClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "import json\n",
    "\n",
    "# ----------- Azure Setup -----------\n",
    "AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT = os.getenv(\"AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT\")\n",
    "AZURE_DOCUMENT_INTELLIGENCE_KEY = os.getenv(\"AZURE_DOCUMENT_INTELLIGENCE_KEY\")\n",
    "\n",
    "if not AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT or not AZURE_DOCUMENT_INTELLIGENCE_KEY:\n",
    "    raise EnvironmentError(\"Please set AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT and AZURE_DOCUMENT_INTELLIGENCE_KEY in your environment variables.\")\n",
    "\n",
    "document_intelligence_client = DocumentIntelligenceClient(\n",
    "    endpoint=AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT,\n",
    "    credential=AzureKeyCredential(AZURE_DOCUMENT_INTELLIGENCE_KEY)\n",
    ")\n",
    "\n",
    "# ----------- OCR Function -----------\n",
    "def process_file_new_ocr(file_path: str) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Extracts text from a PDF using Azure Document Intelligence (prebuilt-read model).\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to the local PDF file.\n",
    "    \n",
    "    Returns:\n",
    "        List[Dict]: A list of dicts with title, page number, and extracted content.\n",
    "    \"\"\"\n",
    "    file_path = Path(file_path)\n",
    "    if not file_path.exists():\n",
    "        raise FileNotFoundError(f\"File not found: {file_path}\")\n",
    "    \n",
    "    logging.info(f\"Processing file: {file_path.name}\")\n",
    "\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        document_bytes = f.read()\n",
    "\n",
    "    poller = document_intelligence_client.begin_analyze_document(\n",
    "        model_id=\"prebuilt-read\",\n",
    "        body=document_bytes,\n",
    "    )\n",
    "    result = poller.result()\n",
    "\n",
    "    attachment_list = []\n",
    "    for page in result.pages:\n",
    "        text = \" \".join([line.content for line in page.lines])\n",
    "        attachment_list.append({\n",
    "            \"title\": file_path.name,\n",
    "            \"pagenum\": page.page_number,\n",
    "            \"content\": text\n",
    "        })\n",
    "\n",
    "    return attachment_list\n",
    "\n",
    "# ----------- Example Usage -----------\n",
    "if __name__ == \"__main__\":\n",
    "    test_file = \"R&D Supplier Brief - Chocolate Coating for Murray Street.pdf\"  # Replace with your actual file name\n",
    "\n",
    "    try:\n",
    "        output = process_file_new_ocr(test_file)\n",
    "        print(json.dumps(output, indent=2))\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting azure-ai-documentintelligence\n",
      "  Downloading azure_ai_documentintelligence-1.0.2-py3-none-any.whl.metadata (53 kB)\n",
      "Requirement already satisfied: isodate>=0.6.1 in /Users/jaydutonde/Library/Python/3.9/lib/python/site-packages (from azure-ai-documentintelligence) (0.6.1)\n",
      "Requirement already satisfied: azure-core>=1.30.0 in /Users/jaydutonde/Library/Python/3.9/lib/python/site-packages (from azure-ai-documentintelligence) (1.34.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /Users/jaydutonde/Library/Python/3.9/lib/python/site-packages (from azure-ai-documentintelligence) (4.12.2)\n",
      "Requirement already satisfied: requests>=2.21.0 in /Users/jaydutonde/Library/Python/3.9/lib/python/site-packages (from azure-core>=1.30.0->azure-ai-documentintelligence) (2.32.3)\n",
      "Requirement already satisfied: six>=1.11.0 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from azure-core>=1.30.0->azure-ai-documentintelligence) (1.15.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/jaydutonde/Library/Python/3.9/lib/python/site-packages (from requests>=2.21.0->azure-core>=1.30.0->azure-ai-documentintelligence) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/jaydutonde/Library/Python/3.9/lib/python/site-packages (from requests>=2.21.0->azure-core>=1.30.0->azure-ai-documentintelligence) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/jaydutonde/Library/Python/3.9/lib/python/site-packages (from requests>=2.21.0->azure-core>=1.30.0->azure-ai-documentintelligence) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/jaydutonde/Library/Python/3.9/lib/python/site-packages (from requests>=2.21.0->azure-core>=1.30.0->azure-ai-documentintelligence) (2025.1.31)\n",
      "Downloading azure_ai_documentintelligence-1.0.2-py3-none-any.whl (106 kB)\n",
      "Installing collected packages: azure-ai-documentintelligence\n",
      "Successfully installed azure-ai-documentintelligence-1.0.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install azure-ai-documentintelligence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
