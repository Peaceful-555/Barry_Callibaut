{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Calling OpenAI API with deployment: gpt-4o, Retry: 1\n",
      "INFO:__main__:OPENAI CALL MESSAGE: Retry 1 | Func: extract_attributes_from_rd_brief | Duration: 10.237s completion_tokens: 910 | prompt_tokens: 2035 | total_tokens: 2945 | completion_tokens_details: {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0} | prompt_tokens_details: {'audio_tokens': 0, 'cached_tokens': 1024} | \n",
      "INFO:__main__:Token Usage Summary: {'extract_attributes_from_rd_brief': 2945}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ OpenAI Response:\n",
      " {\n",
      "  \"allergen_items\": {\n",
      "    \"explicit\": {},\n",
      "    \"inferred\": {\n",
      "      \"Milk\": {\n",
      "        \"value\": \"Present\",\n",
      "        \"source\": \"inferred\",\n",
      "        \"note\": \"White chocolate typically contains milk solids.\"\n",
      "      },\n",
      "      \"Soy\": {\n",
      "        \"value\": \"May be present\",\n",
      "        \"source\": \"inferred\",\n",
      "        \"note\": \"Soy lecithin is commonly used as an emulsifier in chocolate products.\"\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  \"claims_certifications\": {\n",
      "    \"explicit\": {},\n",
      "    \"inferred\": {\n",
      "      \"Non-GMO\": {\n",
      "        \"value\": \"Not specified\",\n",
      "        \"source\": \"inferred\",\n",
      "        \"note\": \"No explicit mention of GMO-free claims in the document.\"\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  \"ingredients_composition\": {\n",
      "    \"explicit\": {},\n",
      "    \"inferred\": {\n",
      "      \"White Chocolate Base\": {\n",
      "        \"value\": \"White chocolate\",\n",
      "        \"source\": \"inferred\",\n",
      "        \"note\": \"Product descriptions consistently refer to white chocolate.\"\n",
      "      },\n",
      "      \"Emulsifiers\": {\n",
      "        \"value\": \"Likely includes lecithin\",\n",
      "        \"source\": \"inferred\",\n",
      "        \"note\": \"Lecithin is a common emulsifier in chocolate products.\"\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  \"legal_specifications\": {\n",
      "    \"explicit\": {},\n",
      "    \"inferred\": {\n",
      "      \"Export Compliance\": {\n",
      "        \"value\": \"Canada and US\",\n",
      "        \"source\": \"inferred\",\n",
      "        \"note\": \"Samples are being sent to Canadian and US offices for evaluation.\"\n",
      "      },\n",
      "      \"Tariff Restrictions\": {\n",
      "        \"value\": \"Compound chip not approved for sale in Canada\",\n",
      "        \"source\": \"explicit\",\n",
      "        \"note\": \"Document explicitly mentions tariff restrictions for compound chip.\"\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  \"nutritional_values\": {\n",
      "    \"explicit\": {},\n",
      "    \"inferred\": {\n",
      "      \"Fat Content\": {\n",
      "        \"value\": \"Not specified\",\n",
      "        \"source\": \"inferred\",\n",
      "        \"note\": \"No explicit mention of fat content in the document.\"\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  \"packaging_information\": {\n",
      "    \"explicit\": {},\n",
      "    \"inferred\": {\n",
      "      \"Packaging Format\": {\n",
      "        \"value\": \"Boxes and pallets\",\n",
      "        \"source\": \"inferred\",\n",
      "        \"note\": \"Document mentions products being packed in boxes and pallets.\"\n",
      "      },\n",
      "      \"Pack Sizes\": {\n",
      "        \"value\": \"4 kg, 10 lbs, 22 lbs, 30 lbs\",\n",
      "        \"source\": \"explicit\",\n",
      "        \"note\": \"Pack sizes are explicitly listed for various products.\"\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  \"sales_commercial\": {\n",
      "    \"explicit\": {\n",
      "      \"Pricing\": {\n",
      "        \"value\": \"Various prices per kg for different products\",\n",
      "        \"source\": \"explicit\"\n",
      "      },\n",
      "      \"MOQ\": {\n",
      "        \"value\": \"Not specified\",\n",
      "        \"source\": \"explicit\"\n",
      "      }\n",
      "    },\n",
      "    \"inferred\": {\n",
      "      \"Market Target\": {\n",
      "        \"value\": \"Canada and US\",\n",
      "        \"source\": \"inferred\",\n",
      "        \"note\": \"Samples are being sent to Canadian and US offices for evaluation.\"\n",
      "      },\n",
      "      \"Sales Channel\": {\n",
      "        \"value\": \"Foodservice and retail\",\n",
      "        \"source\": \"inferred\",\n",
      "        \"note\": \"Products are described as toppings and decor items, suitable for foodservice and retail.\"\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  \"technical_specifications\": {\n",
      "    \"explicit\": {},\n",
      "    \"inferred\": {\n",
      "      \"Product_Type\": {\n",
      "        \"value\": \"White chocolate blossoms, curls, chips\",\n",
      "        \"source\": \"inferred\",\n",
      "        \"note\": \"Document lists multiple white chocolate products.\"\n",
      "      },\n",
      "      \"Base_Type\": {\n",
      "        \"value\": \"White chocolate\",\n",
      "        \"source\": \"inferred\",\n",
      "        \"note\": \"All products are described as white chocolate.\"\n",
      "      },\n",
      "      \"Moulding_Type\": {\n",
      "        \"value\": \"Blossoms, curls, chips\",\n",
      "        \"source\": \"inferred\",\n",
      "        \"note\": \"Document specifies these shapes for the products.\"\n",
      "      },\n",
      "      \"Components_Specifications\": {\n",
      "        \"value\": \"Likely includes emulsifiers such as lecithin\",\n",
      "        \"source\": \"inferred\",\n",
      "        \"note\": \"Lecithin is commonly used in chocolate products.\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "âœ… Extracted attributes saved to 'extracted_attributes00170112.json'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import logging\n",
    "from dotenv import load_dotenv\n",
    "from typing import List, Dict\n",
    "from pathlib import Path\n",
    "from azure.identity import ClientSecretCredential\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.documentintelligence import DocumentIntelligenceClient\n",
    "from langchain_openai import AzureChatOpenAI, AzureOpenAIEmbeddings\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "# ------------------ Load environment variables ------------------\n",
    "load_dotenv()\n",
    "\n",
    "# ------------------ Logging setup ------------------\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# ------------------ Azure Credentials ------------------\n",
    "credential = ClientSecretCredential(\n",
    "    tenant_id=os.getenv(\"AZURE_TENANT_ID\"),\n",
    "    client_id=os.getenv(\"AZURE_CLIENT_ID\"),\n",
    "    client_secret=os.getenv(\"AZURE_CLIENT_SECRET\"),\n",
    ")\n",
    "\n",
    "# ------------------ Globals ------------------\n",
    "TOKEN_USAGE = {}\n",
    "TOTAL_API_CALL = 0\n",
    "AZURE_OPENAI_DEPLOYMENT = os.getenv(\"AZURE_OPENAI_DEPLOYMENT\")\n",
    "\n",
    "# ------------------ Azure Document Intelligence Client ------------------\n",
    "AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT = os.getenv(\"AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT\")\n",
    "AZURE_DOCUMENT_INTELLIGENCE_KEY = os.getenv(\"AZURE_DOCUMENT_INTELLIGENCE_KEY\")\n",
    "\n",
    "if not AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT or not AZURE_DOCUMENT_INTELLIGENCE_KEY:\n",
    "    raise EnvironmentError(\"Missing Azure Document Intelligence credentials\")\n",
    "\n",
    "document_intelligence_client = DocumentIntelligenceClient(\n",
    "    endpoint=AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT,\n",
    "    credential=AzureKeyCredential(AZURE_DOCUMENT_INTELLIGENCE_KEY)\n",
    ")\n",
    "\n",
    "# ------------------ OCR Function ------------------\n",
    "def process_file_new_ocr(file_path: str) -> List[Dict]:\n",
    "    file_path = Path(file_path)\n",
    "    if not file_path.exists():\n",
    "        raise FileNotFoundError(f\"File not found: {file_path}\")\n",
    "\n",
    "    logging.info(f\"Processing file: {file_path.name}\")\n",
    "\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        document_bytes = f.read()\n",
    "\n",
    "    poller = document_intelligence_client.begin_analyze_document(\n",
    "        model_id=\"prebuilt-read\",\n",
    "        body=document_bytes,\n",
    "    )\n",
    "    result = poller.result()\n",
    "\n",
    "    attachment_list = []\n",
    "    for page in result.pages:\n",
    "        text = \" \".join([line.content for line in page.lines])\n",
    "        attachment_list.append({\n",
    "            \"title\": file_path.name,\n",
    "            \"pagenum\": page.page_number,\n",
    "            \"content\": text\n",
    "        })\n",
    "\n",
    "    return attachment_list\n",
    "\n",
    "# ------------------ Azure OpenAI LLM Clients ------------------\n",
    "AzureChatOpenAI.model_rebuild()\n",
    "\n",
    "def llm():\n",
    "    access_token = credential.get_token(\"https://cognitiveservices.azure.com/.default\").token\n",
    "    return AzureChatOpenAI(\n",
    "        azure_deployment=AZURE_OPENAI_DEPLOYMENT,\n",
    "        api_version=os.getenv(\"AZURE_API_VERSION\"),\n",
    "        temperature=0,\n",
    "        max_tokens=None,\n",
    "        timeout=None,\n",
    "        max_retries=2,\n",
    "        openai_api_key=access_token,\n",
    "        azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    )\n",
    "\n",
    "def openai_llm():\n",
    "    access_token = credential.get_token(\"https://cognitiveservices.azure.com/.default\").token\n",
    "    return AzureOpenAI(\n",
    "        azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "        api_version=os.getenv(\"AZURE_API_VERSION\"),\n",
    "        api_key=access_token,\n",
    "    )\n",
    "\n",
    "def embeddings():\n",
    "    access_token = credential.get_token(\"https://cognitiveservices.azure.com/.default\").token\n",
    "    return AzureOpenAIEmbeddings(\n",
    "        model=os.getenv(\"EMBEDDING_AZURE_OPENAI_DEPLOYMENT\"),\n",
    "        azure_endpoint=os.getenv(\"EMBEDDING_AZURE_OPENAI_ENDPOINT\"),\n",
    "        openai_api_version=os.getenv(\"AZURE_API_VERSION\"),\n",
    "        api_key=access_token,\n",
    "    )\n",
    "\n",
    "# ------------------ OpenAI Call Utilities ------------------\n",
    "def add_token_usage_logs(llm_output, message=\"\"):\n",
    "    token_usage_string = \"\"\n",
    "    for key, value in llm_output.to_dict().get(\"usage\", {}).items():\n",
    "        token_usage_string += f\"{key}: {value} | \"\n",
    "    logger.info(f\"{message} {token_usage_string}\")\n",
    "    return llm_output.to_dict().get(\"usage\", {}).get(\"total_tokens\", 0)\n",
    "\n",
    "def openai_call(sys_prompt, prompt_struc, deployment_name=AZURE_OPENAI_DEPLOYMENT, additional_message=\"\"):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": sys_prompt},\n",
    "        {\"role\": \"user\", \"content\": prompt_struc},\n",
    "    ]\n",
    "    return _call_openai(messages, deployment_name, additional_message)\n",
    "\n",
    "def _call_openai(messages, deployment_name, additional_message):\n",
    "    global TOTAL_API_CALL\n",
    "    max_retries = 5\n",
    "    for current_retry in range(max_retries):\n",
    "        try:\n",
    "            time.sleep(5)\n",
    "            logger.info(f\"Calling OpenAI API with deployment: {deployment_name}, Retry: {current_retry + 1}\")\n",
    "            start_time = time.time()\n",
    "            response = openai_llm().chat.completions.create(\n",
    "                model=deployment_name,\n",
    "                messages=messages,\n",
    "                temperature=0,\n",
    "            )\n",
    "            TOTAL_API_CALL += 1\n",
    "            duration = round(time.time() - start_time, 3)\n",
    "            output = response.choices[0].message.content\n",
    "            if output:\n",
    "                msg = f\"OPENAI CALL MESSAGE: Retry {current_retry + 1} | Func: {additional_message} | Duration: {duration}s\"\n",
    "                total_tokens = add_token_usage_logs(response, message=msg)\n",
    "                TOKEN_USAGE[additional_message] = TOKEN_USAGE.get(additional_message, 0) + total_tokens\n",
    "                logger.info(f\"Token Usage Summary: {TOKEN_USAGE}\")\n",
    "                print(\"\\nðŸ”¹ OpenAI Response:\\n\", output)\n",
    "                return output\n",
    "        except Exception as e:\n",
    "            logger.error(f\"OpenAI Call Error: {e}\")\n",
    "    logger.warning(\"Maximum retries reached. No response returned.\")\n",
    "    return None\n",
    "\n",
    "# ------------------ MAIN EXECUTION BLOCK ------------------\n",
    "if __name__ == \"__main__\":\n",
    "    test_file = \"R&D Supplier Brief - Chocolate Coating for Murray Street.pdf\"\n",
    "\n",
    "    try:\n",
    "        ocr_pages = process_file_new_ocr(test_file)\n",
    "        extracted_text = \"\\n\".join([p[\"content\"] for p in ocr_pages])\n",
    "\n",
    "        system_prompt = \"\"\"\n",
    "You are a domain-aware assistant that extracts structured product development attributes from customer R&D or supplier brief documents.\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸŽ¯ Your Role:\n",
    "You are interpreting a **customer brief** â€” a document that includes both direct requirements and contextual information. Your job is to:\n",
    "1. Extract **explicit** attributes: those that are **directly requested by the customer** in the brief.\n",
    "2. Extract **inferred** attributes: high-confidence values **logically implied** by the briefâ€™s context, product type, or regulatory standards, with a supporting `\"note\"`.\n",
    "\n",
    "âš ï¸ Just because a value is mentioned in the brief does **not** mean it is \"explicit\". Only customer **requested** attributes qualify as explicit.\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ“Œ Mandatory Attributes to Always Return:\n",
    "Regardless of how they appear in the brief, always include the following attributes in your output:\n",
    "- `Product_Type`\n",
    "- `Base_Type` (e.g., dark, milk, white)\n",
    "- `Moulding_Type` (e.g., chips, blocks, liquid)\n",
    "- `Components_Specifications` (e.g., emulsifiers, lecithin, PGPR)\n",
    "- `Fat` (Total fat %, g/100g, etc.)\n",
    "- `pH` (if mentioned in any context)\n",
    "\n",
    "If these are **explicitly requested**, place them under `\"explicit\"`.\n",
    "\n",
    "If they are **mentioned but not requested**, or not mentioned at all but can be deduced, place them under `\"inferred\"` with a justification in `\"note\"`.\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ—‚ï¸ Output Categories:\n",
    "Group extracted attributes under the following **8 standard categories**, each containing:\n",
    "- `\"explicit\"`: only those clearly **requested by the customer**\n",
    "- `\"inferred\"`: high-confidence deductions with `\"note\"`\n",
    "\n",
    "1. allergen_items  \n",
    "2. claims_certifications  \n",
    "3. ingredients_composition  \n",
    "4. legal_specifications  \n",
    "5. nutritional_values  \n",
    "6. packaging_information  \n",
    "7. sales_commercial  \n",
    "8. technical_specifications\n",
    "\n",
    "---\n",
    "\n",
    "### Also include **explicit attributes based on product-type logic**::\n",
    "\n",
    "#### Chocolate Type-specific (Dark / Milk / White):\n",
    "- Total fat (% or g/100g)\n",
    "- Minimum dry cocoa solids (%)\n",
    "- Dry fat-free cocoa solids (%)\n",
    "- Milkfat (%) â€“ for milk/white chocolate\n",
    "- Dry milk solids (%)\n",
    "- Fineness type (e.g., FP or micrometer)\n",
    "- Norm linear viscosity (mPa.s)\n",
    "- Casson viscosity (mPa.s)\n",
    "- Yield value (Pa)\n",
    "\n",
    "#### ðŸ¬ Moulding/Shape Specifics:\n",
    "- Length, Width, Height\n",
    "- Vibration (drops)\n",
    "- Primary Count or Count/Unit\n",
    "- Sieve fraction (if relevant)\n",
    "\n",
    "#### ðŸ§ª Compound/Fillings:\n",
    "- Check for â€œcontains hydrogenatedâ€ or hydrogenated fats content\n",
    "\n",
    "#### ðŸ¥œ If Nuts are Mentioned:\n",
    "- % of nuts or quantity\n",
    "\n",
    "#### ðŸŒ Export Targets (e.g., EU, US, China):\n",
    "- Legal declaration required\n",
    "- Country-specific regulatory compliance\n",
    "- Typical cocoa content\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ” Inference Guidelines:\n",
    "\n",
    "Use domain knowledge to **infer high-confidence values**:\n",
    "\n",
    "#### âœ… ingredients_composition\n",
    "- PGPR or lecithin implies vegetable fats or emulsifiers\n",
    "- Codex mention â†’ infer standard ranges for cocoa, milk solids, and sugar\n",
    "- If PGPR â‰¤ 0.5%, infer presence of vegetable fats (as PGPR works with them)\n",
    "\n",
    "#### âœ… technical_specifications\n",
    "- Enrobing or frozen products â†’ infer â€œFreezer Stabilityâ€, â€œSnap Textureâ€\n",
    "- Melting, flow, viscosity mentions â†’ infer â€œFlowabilityâ€ or â€œProcessing Characteristicsâ€\n",
    "- Export shipping â†’ infer â€œShelf Stabilityâ€\n",
    "\n",
    "#### âœ… claims_certifications\n",
    "- RSPO, FSC, Rainforest â†’ infer sustainable sourcing\n",
    "- â€œNon-GMOâ€, â€œNo artificial preservatives/flavors/sweetenersâ€ â†’ infer all â€œfree-fromâ€ claims\n",
    "\n",
    "#### âœ… legal_specifications\n",
    "- Codex, EU, FDA, or US law references â†’ infer â€œLegal Declaration Requiredâ€\n",
    "- Export references â†’ infer country-level compliance\n",
    "\n",
    "#### âœ… nutritional_values\n",
    "- â€œNo sugar addedâ€ â†’ infer â€œLow Sugar Claimâ€\n",
    "- High fat/caloric composition â†’ infer â€œHigh Energy Densityâ€\n",
    "\n",
    "#### âœ… packaging_information\n",
    "- Box, pouch, bag, sachet â†’ infer â€œPackaging Formatâ€ and durability\n",
    "- FSC or eco-labels â†’ infer â€œSustainable Packaging Complianceâ€\n",
    "\n",
    "#### âœ… sales_commercial\n",
    "- Customer/market-specific formats â†’ infer â€œMarket Targetâ€, â€œSales Channelâ€\n",
    "- Mention of MOQ, pricing, volume â†’ infer commercial specs (e.g., â€œMOQâ€, â€œIndicative Volumesâ€)\n",
    "\n",
    "#### âœ… allergen_items\n",
    "- If allergen list (e.g., milk, soy, nuts) is stated or avoided â†’ infer inclusion/exclusion\n",
    "- â€œMay contain tracesâ€¦â€ â†’ infer â€œCross-Contamination Riskâ€\n",
    "\n",
    "---\n",
    "\n",
    "### âš ï¸ Output Rules:\n",
    "- Only include `\"explicit\"` if clearly requested by the customer.\n",
    "- Include the mandatory 6 attributes always in the output \n",
    "- Do **not fabricate** values without strong support.\n",
    "- Return clean **valid JSON** only â€” no markdown, comments, or explanations.\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… Output Format:\n",
    "Return structured JSON in this format:\n",
    "\n",
    "{\n",
    "  \"category_name\": {\n",
    "    \"explicit\": {\n",
    "      \"Attribute Name\": {\n",
    "        \"value\": \"...\",\n",
    "        \"source\": \"explicit\"\n",
    "      }\n",
    "    },\n",
    "    \"inferred\": {\n",
    "      \"Attribute Name\": {\n",
    "        \"value\": \"...\",\n",
    "        \"source\": \"inferred\",\n",
    "        \"note\": \"brief justification\"\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "Each `category_name` must match one of the 8 categories above.\n",
    "\"\"\"\n",
    "\n",
    "        user_prompt = f\"\"\"Here is the extracted text from an R&D document:\n",
    "\n",
    "--- START OF DOCUMENT ---\n",
    "{extracted_text}\n",
    "\n",
    "--- END OF DOCUMENT ---\n",
    "\n",
    "Now extract and categorize the relevant structured attributes and their values into 8 categories, each with explicit and inferred sections, as per the guidelines. Provide only valid JSON output without commentary or markdown formatting.\n",
    "\"\"\"\n",
    "\n",
    "        result = openai_call(\n",
    "            sys_prompt=system_prompt,\n",
    "            prompt_struc=user_prompt,\n",
    "            additional_message=\"extract_attributes_from_rd_brief\"\n",
    "        )\n",
    "\n",
    "        if result:\n",
    "            with open(\"extracted_attributes00170112.json\", \"w\") as f:\n",
    "                json.dump(json.loads(result), f, indent=2)\n",
    "                print(\"\\nâœ… Extracted attributes saved to 'extracted_attributes00170112.json'\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Excel saved to: structured_attribute_output_00170112.xlsx\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.utils import get_column_letter\n",
    "from openpyxl.styles import Alignment\n",
    "\n",
    "CATEGORIES = [\n",
    "    \"allergen_items\", \"claims_certifications\", \"ingredients_composition\",\n",
    "    \"legal_specifications\", \"nutritional_values\", \"packaging_information\",\n",
    "    \"sales_commercial\", \"technical_specifications\"\n",
    "]\n",
    "\n",
    "def format_as_json_string(data: dict) -> str:\n",
    "    if not data:\n",
    "        return \"{}\"\n",
    "    return json.dumps(data, indent=2, ensure_ascii=False)\n",
    "\n",
    "def json_to_structured_excel(json_file: str, output_excel: str):\n",
    "    with open(json_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    rows = []\n",
    "    for idx, category in enumerate(CATEGORIES, start=1):\n",
    "        explicit_attrs = data.get(category, {}).get(\"explicit\", {})\n",
    "        inferred_attrs = data.get(category, {}).get(\"inferred\", {})\n",
    "\n",
    "        row = {\n",
    "            \"S. No.\": idx,\n",
    "            \"Category_Name\": category,\n",
    "            \"Explicit Attributes\": format_as_json_string(explicit_attrs),\n",
    "            \"Inferred Attributes\": format_as_json_string(inferred_attrs)\n",
    "        }\n",
    "        rows.append(row)\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.to_excel(output_excel, index=False)\n",
    "\n",
    "    # Adjust formatting using openpyxl\n",
    "    wb = load_workbook(output_excel)\n",
    "    ws = wb.active\n",
    "\n",
    "    # Set column widths (40 characters wide) and wrap text\n",
    "    for col in range(1, ws.max_column + 1):\n",
    "        col_letter = get_column_letter(col)\n",
    "        ws.column_dimensions[col_letter].width = 40\n",
    "        for row in range(2, ws.max_row + 1):  # Skip header\n",
    "            cell = ws.cell(row=row, column=col)\n",
    "            cell.alignment = Alignment(wrap_text=True, vertical=\"top\")\n",
    "\n",
    "    # Set row height to 409 for all rows\n",
    "    for row in range(2, ws.max_row + 1):  # Skip header row\n",
    "        ws.row_dimensions[row].height = 409\n",
    "\n",
    "    wb.save(output_excel)\n",
    "    print(f\"âœ… Excel saved to: {output_excel}\")\n",
    "\n",
    "# Example usage\n",
    "json_to_structured_excel(\"extracted_attributes00170112.json\", \"structured_attribute_output_00170112.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Excel file saved to: categorized_attributes_00170112.xlsx\n"
     ]
    }
   ],
   "source": [
    "# import json\n",
    "# import pandas as pd\n",
    "\n",
    "# # Define the 8 attribute categories\n",
    "# CATEGORIES = [\n",
    "#     \"allergen_items\", \"claims_certifications\", \"ingredients_composition\",\n",
    "#     \"legal_specifications\", \"nutritional_values\", \"packaging_information\",\n",
    "#     \"sales_commercial\", \"technical_specifications\"\n",
    "# ]\n",
    "\n",
    "# def format_value(val):\n",
    "#     if isinstance(val, dict):\n",
    "#         return \"; \".join(f\"{k}: {format_value(v)}\" for k, v in val.items())\n",
    "#     elif isinstance(val, list):\n",
    "#         return \", \".join(str(v) for v in val)\n",
    "#     return str(val)\n",
    "\n",
    "# def convert_structured_attributes(json_file: str, output_excel: str):\n",
    "#     with open(json_file, 'r') as f:\n",
    "#         attributes_data = json.load(f)\n",
    "\n",
    "#     # Prepare a structure to hold all values\n",
    "#     attribute_lookup = {cat: {\"explicit\": {}, \"inferred\": {}} for cat in CATEGORIES}\n",
    "#     all_attribute_names = set()\n",
    "\n",
    "#     # Extract values and track attribute names\n",
    "#     for category in CATEGORIES:\n",
    "#         if category in attributes_data:\n",
    "#             for source_type in [\"explicit\", \"inferred\"]:\n",
    "#                 items = attributes_data[category].get(source_type, {})\n",
    "#                 for attr_name, attr_obj in items.items():\n",
    "#                     value = format_value(attr_obj.get(\"value\", \"\"))\n",
    "#                     attribute_lookup[category][source_type][attr_name] = value\n",
    "#                     all_attribute_names.add(attr_name)\n",
    "\n",
    "#     # Prepare rows\n",
    "#     rows = []\n",
    "#     for attr in sorted(all_attribute_names):\n",
    "#         row = {\"Attribute Name\": attr}\n",
    "#         for category in CATEGORIES:\n",
    "#             row[f\"{category} (explicit)\"] = attribute_lookup[category][\"explicit\"].get(attr, \"\")\n",
    "#             row[f\"{category} (inferred)\"] = attribute_lookup[category][\"inferred\"].get(attr, \"\")\n",
    "#         rows.append(row)\n",
    "\n",
    "#     # Build DataFrame\n",
    "#     df = pd.DataFrame(rows)\n",
    "\n",
    "#     # Ensure all expected columns exist\n",
    "#     all_columns = [\"Attribute Name\"] + [f\"{cat} (explicit)\" for cat in CATEGORIES] + [f\"{cat} (inferred)\" for cat in CATEGORIES]\n",
    "#     for col in all_columns:\n",
    "#         if col not in df.columns:\n",
    "#             df[col] = \"\"\n",
    "\n",
    "#     # Reorder columns\n",
    "#     df = df[all_columns]\n",
    "\n",
    "#     # Export to Excel\n",
    "#     df.to_excel(output_excel, index=False)\n",
    "#     print(f\"âœ… Excel file saved to: {output_excel}\")\n",
    "\n",
    "# # Example usage\n",
    "# convert_structured_attributes(\"extracted_attributes00170112.json\", \"categorized_attributes_00170112.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
